{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MemNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfR7P3Qe8ds"
      },
      "source": [
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YO_Rd8zgOaL",
        "outputId": "e07f42a8-4d91-44b9-8578-ac671a965502"
      },
      "source": [
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1_UIOQgZz4"
      },
      "source": [
        "import tarfile, os\n",
        "\n",
        "with tarfile.open(path) as tar:\n",
        "  tar.extractall()\n",
        "  tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgzxFgUmgi8r",
        "outputId": "4a233ead-22a1-4a5e-d5fb-036cfcc2b3cd"
      },
      "source": [
        "with open(TRAIN_FILE, 'r') as f:\n",
        "  for i, line in enumerate(f.readlines()):\n",
        "    print(line)\n",
        "    if i > 30:\n",
        "      break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "\n",
            "2 John went to the hallway.\n",
            "\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "\n",
            "4 Daniel went back to the hallway.\n",
            "\n",
            "5 Sandra moved to the garden.\n",
            "\n",
            "6 Where is Daniel? \thallway\t4\n",
            "\n",
            "7 John moved to the office.\n",
            "\n",
            "8 Sandra journeyed to the bathroom.\n",
            "\n",
            "9 Where is Daniel? \thallway\t4\n",
            "\n",
            "10 Mary moved to the hallway.\n",
            "\n",
            "11 Daniel travelled to the office.\n",
            "\n",
            "12 Where is Daniel? \toffice\t11\n",
            "\n",
            "13 John went back to the garden.\n",
            "\n",
            "14 John moved to the bedroom.\n",
            "\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "\n",
            "1 Sandra travelled to the office.\n",
            "\n",
            "2 Sandra went to the bathroom.\n",
            "\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "\n",
            "4 Mary went to the bedroom.\n",
            "\n",
            "5 Daniel moved to the hallway.\n",
            "\n",
            "6 Where is Sandra? \tbathroom\t2\n",
            "\n",
            "7 John went to the garden.\n",
            "\n",
            "8 John travelled to the office.\n",
            "\n",
            "9 Where is Sandra? \tbathroom\t2\n",
            "\n",
            "10 Daniel journeyed to the bedroom.\n",
            "\n",
            "11 Daniel travelled to the hallway.\n",
            "\n",
            "12 Where is John? \toffice\t8\n",
            "\n",
            "13 John went to the bedroom.\n",
            "\n",
            "14 John travelled to the office.\n",
            "\n",
            "15 Where is Daniel? \thallway\t11\n",
            "\n",
            "1 Mary went to the bedroom.\n",
            "\n",
            "2 John journeyed to the bathroom.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O0dLv9uhERs"
      },
      "source": [
        "import pprint \n",
        "def read_data(dir):\n",
        "  stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변\n",
        "  story_temp = [] # 현재 시점의 스토리 임시 저장 \n",
        "\n",
        "  with open(dir, 'rb') as lines:\n",
        "    for line in lines:\n",
        "      line = line.decode('utf-8') # 'b' 제거\n",
        "      line = line.strip() # '\\n' 제거\n",
        "      idx, text = line.split(' ', 1) # id number 분리\n",
        "\n",
        "      if int(idx) == 1:\n",
        "        story_temp = []\n",
        "\n",
        "      if '\\t' in text: # 질문, \\t, 답변 인 경우 \n",
        "        question, answer, _ = text.split('\\t')\n",
        "        stories.append([x for x in story_temp if x])\n",
        "        questions.append(question)\n",
        "        answers.append(answer)\n",
        "      else: # 현재 읽는 줄이 스토리인 경우 \n",
        "        story_temp.append(text)\n",
        "  \n",
        "  return stories, questions, answers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4tYG_4jglyP"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLXMJaWxmi5"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wExrFlNsx8D3",
        "outputId": "e2129ce1-5b06-4914-c43c-73202e2b0d0c"
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XUSN3oHyJ_T"
      },
      "source": [
        "def print_data(stories, questions, answers, idx):\n",
        "  pprint.pprint(stories[idx])\n",
        "  pprint.pprint(questions[idx])\n",
        "  pprint.pprint(answers[idx])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxbqIZQKyY7E",
        "outputId": "6e64b0af-c4b9-4534-f3ba-0b371f707d1c"
      },
      "source": [
        "print_data(train_stories, train_questions, train_answers, 0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mary moved to the bathroom.', 'John went to the hallway.']\n",
            "'Where is Mary? '\n",
            "'bathroom'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU7S-dHby8AE"
      },
      "source": [
        "import re \n",
        "\n",
        "def tokenize(sent):\n",
        "  return [x.strip() for x in re.split('(\\w+)', sent) if x.strip()]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSRhJ-0CgBVC"
      },
      "source": [
        "import numpy as np\n",
        "from nltk import FreqDist # 단어 빈도를 인코딩 하는데 사용한다\n",
        "from functools import reduce # iterable 의 요소들을 function 에 대입하여 결국 하나의 결과값을 리턴하는 함수\n",
        "\n",
        "def preprocess_data(train_data, test_data):\n",
        "  counter = FreqDist()\n",
        "\n",
        "  # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "  flatten = lambda data: reduce(lambda x, y: x+y, data)\n",
        "\n",
        "  story_len = []\n",
        "  question_len = []\n",
        "\n",
        "  for stories, questions, answers in [train_data, test_data]:\n",
        "    for story in stories:\n",
        "      stories = tokenize(flatten(story)) # 스토리의 문장들을 하나로 만든 뒤 토크나이즈\n",
        "      story_len.append(len(stories))\n",
        "      for word in stories: # 단어 집합에 단어 추가\n",
        "        counter[word] += 1\n",
        "    \n",
        "    for question in questions:\n",
        "      question = tokenize(question)\n",
        "      question_len.append(len(question))\n",
        "      for word in question:\n",
        "        counter[word] += 1\n",
        "    \n",
        "    for answer in answers:\n",
        "      answer = tokenize(answer)\n",
        "      for word in answer:\n",
        "        counter[word] += 1\n",
        "\n",
        "  # 단어 집합 생성\n",
        "  word2idx = {word: (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "  idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "  # 가장 긴 샘플의 길이\n",
        "  story_max_len = np.max(story_len)\n",
        "  question_max_len = np.max(question_len)\n",
        "\n",
        "  return word2idx, idx2word, story_max_len, question_max_len\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiMuVo2djqRY"
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FdZr8DFjxKX",
        "outputId": "3831c017-60d7-468f-bf85-a0bf7b0e6668"
      },
      "source": [
        "pprint.pprint(word2idx)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 3,\n",
            " '?': 21,\n",
            " 'Daniel': 7,\n",
            " 'John': 6,\n",
            " 'Mary': 8,\n",
            " 'Sandra': 5,\n",
            " 'Where': 19,\n",
            " 'back': 11,\n",
            " 'bathroom': 12,\n",
            " 'bedroom': 18,\n",
            " 'garden': 13,\n",
            " 'hallway': 14,\n",
            " 'is': 20,\n",
            " 'journeyed': 10,\n",
            " 'kitchen': 17,\n",
            " 'moved': 15,\n",
            " 'office': 16,\n",
            " 'the': 2,\n",
            " 'to': 1,\n",
            " 'travelled': 9,\n",
            " 'went': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "figOlJptl9uv"
      },
      "source": [
        "vocab_size = len(word2idx) + 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNck0I_tqP-k",
        "outputId": "be7f8807-f239-4f39-d36f-4f7d307ed872"
      },
      "source": [
        "print('스토리 최대 길이 :', story_max_len)\n",
        "print('질문의 최대 길이 :', question_max_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "스토리 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9xT26VJqX-E"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def vectorize(data, word2idx, story_max_len, question_max_len):\n",
        "  Xs, Xq, Y = [], [], []\n",
        "  flatten = lambda data: reduce(lambda x, y: x+y, data)\n",
        "\n",
        "  stories, questions, answers = data\n",
        "  for story, question, answer in zip(stories, questions, answers):\n",
        "    xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "    xq = [word2idx[w] for w in tokenize(question)]\n",
        "\n",
        "    Xs.append(xs)\n",
        "    Xq.append(xq)\n",
        "    Y.append(word2idx[answer])\n",
        "\n",
        "  return pad_sequences(Xs, maxlen = story_max_len),\\\n",
        "        pad_sequences(Xq, maxlen = question_max_len),\\\n",
        "        to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiXVbggmrpV2"
      },
      "source": [
        "XsTrain, XqTrain, YTrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "XsTest, XqTest, YTest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7HFTIIsr8q0",
        "outputId": "88d5ab8a-79ce-4535-fab6-a26587363e82"
      },
      "source": [
        "print(XsTrain.shape, XqTrain.shape, YTrain.shape)\n",
        "print(XsTest.shape, XqTest.shape, YTest.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22)\n",
            "(1000, 68) (1000, 4) (1000, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SrILm8JsHav"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate \n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhbcSuN-ukPS"
      },
      "source": [
        "train_epoch = 120 \n",
        "batch_size = 32\n",
        "embed_size = 50 \n",
        "lstm_size = 64\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3tRFOOJuvMh",
        "outputId": "b153033d-25ea-4fa3-b56a-96d9e4d54385"
      },
      "source": [
        "input_sequence = layers.Input((story_max_len,))\n",
        "question = layers.Input((question_max_len,))\n",
        "\n",
        "print(f\"Stories : {input_sequence}\")\n",
        "print(f\"Question : {question}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Question : KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU1bmnvnylnt"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O90DTUbgwFRO"
      },
      "source": [
        "스토리를 위한 첫번째 임베딩. Embedding A    \n",
        "(samples, story_max_len, embedding_size ) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9fn8UXvvLtl"
      },
      "source": [
        "story_encoder_a = Sequential()\n",
        "story_encoder_a.add(layers.Embedding(input_dim=vocab_size, output_dim=embed_size))\n",
        "story_encoder_a.add(layers.Dropout(dropout_rate))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDiSPzCRwL3c"
      },
      "source": [
        "스토리를 위한 두번째 임베딩. Embedding C     \n",
        "(samples, story_max_len, question_max_len ) : 임베딩 벡터의 차원을 질문의 최대 길이로 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npVZvwIkv4lp"
      },
      "source": [
        "story_encoder_c = Sequential()\n",
        "story_encoder_c.add(layers.Embedding(input_dim=vocab_size, output_dim=question_max_len))\n",
        "story_encoder_c.add(layers.Dropout(dropout_rate))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yogy22Z4yHi9"
      },
      "source": [
        "질문을 위한 임베딩. Embedding B\n",
        "(samples, question_max_len, embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj1e04xLw-Ap"
      },
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(layers.Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=question_max_len))\n",
        "question_encoder.add(layers.Dropout(dropout_rate))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btISnLNoy2lh"
      },
      "source": [
        "임베딩 과정 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYOLvQEcyG04",
        "outputId": "62ecdf3b-67b8-455a-d3c5-eed7e5bd82f8"
      },
      "source": [
        "story_encoded_a = story_encoder_a(input_sequence)\n",
        "story_encoded_c = story_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print(f\"Story Encoded A - {story_encoded_a}\")\n",
        "print(f\"Story Encoded C - {story_encoded_c}\")\n",
        "print(f\"Question Encoded - {question_encoded}\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story Encoded A - KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
            "Story Encoded C - KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
            "Question Encoded - KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO_oFaBr0ShY"
      },
      "source": [
        "내적을 사용해서 스토리 단어들과 질문 단어들 간의 유사도를 구한다.    \n",
        "(samples, question_max_len, question_max_len)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgz2ZQr9zepx",
        "outputId": "44833352-0d62-4ff8-98bf-c973d3715666"
      },
      "source": [
        "match = layers.dot([story_encoded_a, question_encoded], axes=-1, normalize=False)\n",
        "match = layers.Activation('softmax')(match)\n",
        "print(f\"Match Shape - {match}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match Shape - KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation/truediv:0', description=\"created by layer 'activation'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3BahVPY1_tQ"
      },
      "source": [
        "구한 유사도와 두번째 스토리 임베딩 벡터를 더한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNd2e96e060B",
        "outputId": "90df26e7-3715-430d-ead8-b78bccd78e8e"
      },
      "source": [
        "response = layers.add([match, story_encoded_c])\n",
        "response = layers.Permute((2,1))(response)\n",
        "print(f\"Response Shape - {response}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Response Shape - KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5c5aB6p5By2"
      },
      "source": [
        "더한 결과 벡터를 Question Embed 벡터와 Concatenamte 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7rgnM3M14zG",
        "outputId": "79c2fd87-78c5-4dd5-a003-d720f04ea741"
      },
      "source": [
        "answer = layers.concatenate([response, question_encoded])\n",
        "print(f\"Answer Shape - {answer}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer Shape - KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxmhv8QW7Zp1",
        "outputId": "eba79a7a-bb2c-4a99-b810-10df4b604825"
      },
      "source": [
        "answer"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 4, 118) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_75TsFL5ARX",
        "outputId": "fd027aed-5675-4050-ab01-e155e4eb8033"
      },
      "source": [
        "answer = layers.LSTM(lstm_size)(answer)\n",
        "answer = layers.Dropout(dropout_rate)(answer)\n",
        "answer = layers.Dense(vocab_size)(answer)\n",
        "answer = layers.Activation('softmax')(answer)\n",
        "print(f\"Answer Shape - {answer}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer Shape - KerasTensor(type_spec=TensorSpec(shape=(None, 22), dtype=tf.float32, name=None), name='activation_1/Softmax:0', description=\"created by layer 'activation_1'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58PA6mHW5qPO",
        "outputId": "9f0700cd-90c2-4754-b02a-fd208f56f5bd"
      },
      "source": [
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 50)     1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4, 50)        1100        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 68, 4)        0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 4)      88          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 118)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           46848       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 22)           1430        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M5WZUMz7zB5",
        "outputId": "3c0dba1a-47d3-4796-be77-360a38acca01"
      },
      "source": [
        "history = model.fit([XsTrain, XqTrain],\n",
        "         YTrain, batch_size, train_epoch,\n",
        "         validation_data=([XsTest, XqTest], YTest))\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 6s 12ms/step - loss: 2.0069 - acc: 0.1625 - val_loss: 1.7904 - val_acc: 0.1800\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.6968 - acc: 0.2484 - val_loss: 1.6673 - val_acc: 0.2350\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.6542 - acc: 0.2673 - val_loss: 1.6330 - val_acc: 0.2680\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.6065 - acc: 0.3403 - val_loss: 1.4742 - val_acc: 0.4010\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5013 - acc: 0.4008 - val_loss: 1.4700 - val_acc: 0.4060\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4661 - acc: 0.4205 - val_loss: 1.4817 - val_acc: 0.4050\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4193 - acc: 0.4485 - val_loss: 1.3570 - val_acc: 0.5040\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3507 - acc: 0.4955 - val_loss: 1.3087 - val_acc: 0.5160\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3302 - acc: 0.4939 - val_loss: 1.2822 - val_acc: 0.5130\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3055 - acc: 0.5004 - val_loss: 1.2530 - val_acc: 0.5310\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2799 - acc: 0.5143 - val_loss: 1.2525 - val_acc: 0.5020\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2600 - acc: 0.5051 - val_loss: 1.2187 - val_acc: 0.5250\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2508 - acc: 0.5137 - val_loss: 1.2153 - val_acc: 0.5310\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2155 - acc: 0.5245 - val_loss: 1.2081 - val_acc: 0.5260\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2286 - acc: 0.5200 - val_loss: 1.2009 - val_acc: 0.5220\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2258 - acc: 0.5134 - val_loss: 1.2229 - val_acc: 0.5160\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1880 - acc: 0.5250 - val_loss: 1.1908 - val_acc: 0.5230\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2012 - acc: 0.5234 - val_loss: 1.1884 - val_acc: 0.5200\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1939 - acc: 0.5313 - val_loss: 1.1940 - val_acc: 0.5300\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1685 - acc: 0.5369 - val_loss: 1.1747 - val_acc: 0.5040\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1739 - acc: 0.5260 - val_loss: 1.1749 - val_acc: 0.5260\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1687 - acc: 0.5284 - val_loss: 1.1542 - val_acc: 0.5180\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1615 - acc: 0.5268 - val_loss: 1.1691 - val_acc: 0.5190\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1523 - acc: 0.5263 - val_loss: 1.1630 - val_acc: 0.5140\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1315 - acc: 0.5411 - val_loss: 1.1688 - val_acc: 0.5150\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1332 - acc: 0.5447 - val_loss: 1.1659 - val_acc: 0.5210\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1395 - acc: 0.5242 - val_loss: 1.1609 - val_acc: 0.5140\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1280 - acc: 0.5367 - val_loss: 1.1564 - val_acc: 0.5250\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1006 - acc: 0.5507 - val_loss: 1.1575 - val_acc: 0.5330\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1000 - acc: 0.5457 - val_loss: 1.1354 - val_acc: 0.5280\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0798 - acc: 0.5523 - val_loss: 1.1246 - val_acc: 0.5390\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0604 - acc: 0.5717 - val_loss: 1.0502 - val_acc: 0.6060\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9405 - acc: 0.6477 - val_loss: 0.7833 - val_acc: 0.7370\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7188 - acc: 0.7485 - val_loss: 0.6549 - val_acc: 0.7600\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6299 - acc: 0.7744 - val_loss: 0.6025 - val_acc: 0.7870\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5513 - acc: 0.8020 - val_loss: 0.5319 - val_acc: 0.7920\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4972 - acc: 0.8199 - val_loss: 0.4547 - val_acc: 0.8260\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4384 - acc: 0.8389 - val_loss: 0.4502 - val_acc: 0.8290\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4096 - acc: 0.8525 - val_loss: 0.3910 - val_acc: 0.8600\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3740 - acc: 0.8626 - val_loss: 0.3971 - val_acc: 0.8480\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3719 - acc: 0.8616 - val_loss: 0.3870 - val_acc: 0.8400\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3551 - acc: 0.8655 - val_loss: 0.3680 - val_acc: 0.8580\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3480 - acc: 0.8673 - val_loss: 0.3446 - val_acc: 0.8740\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3108 - acc: 0.8828 - val_loss: 0.3511 - val_acc: 0.8560\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3158 - acc: 0.8797 - val_loss: 0.3376 - val_acc: 0.8730\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2927 - acc: 0.8900 - val_loss: 0.3205 - val_acc: 0.8760\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2935 - acc: 0.8908 - val_loss: 0.3161 - val_acc: 0.8830\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2860 - acc: 0.8952 - val_loss: 0.2947 - val_acc: 0.8940\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2601 - acc: 0.9045 - val_loss: 0.2776 - val_acc: 0.8960\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2398 - acc: 0.9090 - val_loss: 0.2626 - val_acc: 0.9000\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2268 - acc: 0.9144 - val_loss: 0.2577 - val_acc: 0.9020\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2188 - acc: 0.9193 - val_loss: 0.2380 - val_acc: 0.9150\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2177 - acc: 0.9209 - val_loss: 0.2268 - val_acc: 0.9230\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2058 - acc: 0.9236 - val_loss: 0.2249 - val_acc: 0.9190\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1804 - acc: 0.9363 - val_loss: 0.2091 - val_acc: 0.9240\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1727 - acc: 0.9403 - val_loss: 0.1961 - val_acc: 0.9340\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1677 - acc: 0.9415 - val_loss: 0.1971 - val_acc: 0.9380\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1725 - acc: 0.9409 - val_loss: 0.2083 - val_acc: 0.9340\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1533 - acc: 0.9492 - val_loss: 0.1970 - val_acc: 0.9380\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1665 - acc: 0.9391 - val_loss: 0.1958 - val_acc: 0.9380\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1480 - acc: 0.9501 - val_loss: 0.2081 - val_acc: 0.9290\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1455 - acc: 0.9515 - val_loss: 0.1968 - val_acc: 0.9390\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1486 - acc: 0.9492 - val_loss: 0.1690 - val_acc: 0.9430\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1235 - acc: 0.9579 - val_loss: 0.2052 - val_acc: 0.9330\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1164 - acc: 0.9607 - val_loss: 0.1982 - val_acc: 0.9370\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1273 - acc: 0.9586 - val_loss: 0.1763 - val_acc: 0.9430\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1174 - acc: 0.9597 - val_loss: 0.1865 - val_acc: 0.9440\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1117 - acc: 0.9657 - val_loss: 0.1780 - val_acc: 0.9420\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1195 - acc: 0.9616 - val_loss: 0.1843 - val_acc: 0.9400\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1180 - acc: 0.9591 - val_loss: 0.2042 - val_acc: 0.9400\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1322 - acc: 0.9628 - val_loss: 0.1808 - val_acc: 0.9390\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0925 - acc: 0.9689 - val_loss: 0.1904 - val_acc: 0.9390\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1071 - acc: 0.9673 - val_loss: 0.1817 - val_acc: 0.9430\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1141 - acc: 0.9627 - val_loss: 0.2307 - val_acc: 0.9400\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0968 - acc: 0.9668 - val_loss: 0.1732 - val_acc: 0.9380\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0919 - acc: 0.9700 - val_loss: 0.1755 - val_acc: 0.9450\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0901 - acc: 0.9695 - val_loss: 0.1860 - val_acc: 0.9460\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0890 - acc: 0.9736 - val_loss: 0.1938 - val_acc: 0.9420\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0847 - acc: 0.9736 - val_loss: 0.1758 - val_acc: 0.9440\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0831 - acc: 0.9723 - val_loss: 0.1775 - val_acc: 0.9480\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0770 - acc: 0.9749 - val_loss: 0.1837 - val_acc: 0.9470\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0768 - acc: 0.9760 - val_loss: 0.2152 - val_acc: 0.9370\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0780 - acc: 0.9730 - val_loss: 0.1742 - val_acc: 0.9460\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0743 - acc: 0.9745 - val_loss: 0.1822 - val_acc: 0.9460\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0746 - acc: 0.9791 - val_loss: 0.1870 - val_acc: 0.9490\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0670 - acc: 0.9796 - val_loss: 0.1640 - val_acc: 0.9570\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0664 - acc: 0.9785 - val_loss: 0.1602 - val_acc: 0.9560\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0683 - acc: 0.9778 - val_loss: 0.1581 - val_acc: 0.9570\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0719 - acc: 0.9787 - val_loss: 0.1664 - val_acc: 0.9530\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0568 - acc: 0.9797 - val_loss: 0.1714 - val_acc: 0.9530\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0670 - acc: 0.9796 - val_loss: 0.1606 - val_acc: 0.9570\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0549 - acc: 0.9829 - val_loss: 0.1442 - val_acc: 0.9590\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0646 - acc: 0.9803 - val_loss: 0.1447 - val_acc: 0.9550\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0683 - acc: 0.9806 - val_loss: 0.1789 - val_acc: 0.9450\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0624 - acc: 0.9814 - val_loss: 0.1526 - val_acc: 0.9580\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0708 - acc: 0.9793 - val_loss: 0.1508 - val_acc: 0.9580\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0572 - acc: 0.9846 - val_loss: 0.1423 - val_acc: 0.9540\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0655 - acc: 0.9818 - val_loss: 0.1618 - val_acc: 0.9610\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0650 - acc: 0.9802 - val_loss: 0.1663 - val_acc: 0.9590\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0521 - acc: 0.9851 - val_loss: 0.1722 - val_acc: 0.9580\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0524 - acc: 0.9833 - val_loss: 0.1547 - val_acc: 0.9590\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0509 - acc: 0.9836 - val_loss: 0.1653 - val_acc: 0.9600\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0496 - acc: 0.9823 - val_loss: 0.1331 - val_acc: 0.9580\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0510 - acc: 0.9832 - val_loss: 0.1279 - val_acc: 0.9640\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0600 - acc: 0.9844 - val_loss: 0.1308 - val_acc: 0.9590\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0504 - acc: 0.9845 - val_loss: 0.1431 - val_acc: 0.9550\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0417 - acc: 0.9869 - val_loss: 0.1289 - val_acc: 0.9620\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0363 - acc: 0.9888 - val_loss: 0.1381 - val_acc: 0.9580\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0573 - acc: 0.9852 - val_loss: 0.1190 - val_acc: 0.9630\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0579 - acc: 0.9859 - val_loss: 0.1542 - val_acc: 0.9550\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0462 - acc: 0.9862 - val_loss: 0.1331 - val_acc: 0.9600\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0337 - acc: 0.9886 - val_loss: 0.1553 - val_acc: 0.9620\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0439 - acc: 0.9856 - val_loss: 0.1428 - val_acc: 0.9640\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0530 - acc: 0.9868 - val_loss: 0.1667 - val_acc: 0.9610\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0429 - acc: 0.9877 - val_loss: 0.1350 - val_acc: 0.9640\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0435 - acc: 0.9868 - val_loss: 0.1289 - val_acc: 0.9690\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0449 - acc: 0.9871 - val_loss: 0.1228 - val_acc: 0.9670\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0476 - acc: 0.9869 - val_loss: 0.1335 - val_acc: 0.9640\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0472 - acc: 0.9854 - val_loss: 0.1233 - val_acc: 0.9670\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0438 - acc: 0.9891 - val_loss: 0.1236 - val_acc: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJZbeTA8AOU"
      },
      "source": [
        "print(f\"테스트 정확도 - {model.evaluate([XsTest, XqTest], YTest)[1]}\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuaYXu1xtxaD"
      },
      "source": [
        "yTest = np.argmax(YTest, axis=1)\n",
        "yTest_ = model.predict([XsTest, XqTest])\n",
        "yTest2_ = np.argmax(yTest_, axis=1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixa61JCtuGye",
        "outputId": "49582c0a-d1cb-4149-e422-6a9c697b030d"
      },
      "source": [
        "print(yTest, yTest_, yTest2_)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14 12 17 14 17 14 13 14 16 16 17 13 16 18 18 17 13 17 16 17 14 16 16 14\n",
            " 18 18 18 17 17 17 14 16 17 17 12 16 12 13 17 18 12 13 12 14 13 17 14 12\n",
            " 16 18 18 16 13 13 17 18 17 14 13 14 14 16 12 13 13 17 17 12 16 16 13 14\n",
            " 13 18 12 17 17 17 14 16 13 12 18 13 16 13 13 14 17 17 12 12 14 12 12 17\n",
            " 17 17 18 18 18 12 16 13 13 14 18 12 16 18 12 12 17 14 17 13 16 17 12 16\n",
            " 18 12 18 14 18 16 13 13 13 12 13 14 12 13 17 12 16 17 12 12 16 14 14 16\n",
            " 18 17 17 17 17 17 13 13 12 16 18 12 13 18 16 14 18 18 18 13 12 13 13 13\n",
            " 17 18 16 16 13 12 12 16 17 18 16 16 14 14 14 14 18 12 16 13 17 16 14 17\n",
            " 13 14 14 13 16 17 12 18 14 16 16 18 14 12 17 14 12 14 12 18 14 18 12 18\n",
            " 12 14 14 12 12 14 17 14 18 16 14 13 12 12 16 13 14 16 14 18 18 18 18 16\n",
            " 14 17 13 13 17 17 13 13 13 13 18 16 12 12 18 18 16 16 17 13 13 16 14 16\n",
            " 16 12 13 18 12 18 17 16 16 17 12 16 17 14 16 12 12 13 16 16 13 16 12 16\n",
            " 13 12 17 17 18 17 17 13 13 14 14 12 12 12 12 16 14 13 12 16 16 17 13 13\n",
            " 16 18 13 16 18 16 16 13 13 17 17 13 13 12 18 13 13 18 17 16 17 18 18 16\n",
            " 14 16 14 14 14 13 16 17 13 16 14 14 17 17 18 13 13 18 18 12 16 14 13 14\n",
            " 13 12 13 13 13 13 13 14 14 14 14 14 13 13 16 18 17 12 12 18 12 18 18 16\n",
            " 16 17 16 16 16 17 17 14 12 18 16 16 18 16 12 13 18 13 18 17 16 17 14 18\n",
            " 13 17 18 13 12 14 16 18 18 17 14 12 14 14 12 14 18 17 17 16 18 18 16 17\n",
            " 17 17 16 13 17 12 18 13 18 14 12 13 18 13 18 14 13 17 17 17 17 13 12 17\n",
            " 18 14 13 14 12 13 18 16 13 13 18 18 18 16 14 16 16 12 17 13 12 17 13 12\n",
            " 18 18 14 14 13 18 12 14 18 12 17 18 18 13 13 17 17 18 14 14 17 13 12 14\n",
            " 12 17 18 16 16 18 18 16 18 18 16 12 12 18 14 13 16 16 14 14 13 14 16 13\n",
            " 13 14 13 13 13 16 12 13 18 14 14 18 13 16 14 14 17 13 17 17 14 18 18 12\n",
            " 16 18 17 14 17 18 18 18 13 18 13 17 18 12 12 17 18 18 18 18 17 17 16 12\n",
            " 18 14 18 18 14 14 13 17 18 18 13 14 18 18 16 14 16 13 12 12 16 16 13 18\n",
            " 18 18 17 17 16 13 17 14 13 18 17 16 12 13 12 16 17 14 17 16 13 16 16 17\n",
            " 12 18 12 12 18 18 12 18 18 17 13 13 13 17 14 12 13 13 18 16 13 13 14 16\n",
            " 17 17 12 13 17 17 13 12 17 17 13 17 17 17 13 18 18 12 16 16 16 16 18 18\n",
            " 16 12 17 12 16 14 14 14 17 17 17 16 12 13 12 16 12 14 13 12 12 16 13 13\n",
            " 13 18 17 18 14 14 12 12 16 14 14 12 16 14 13 13 17 17 14 13 14 16 14 16\n",
            " 13 14 13 16 16 13 16 12 13 12 18 18 14 16 18 14 12 12 12 17 13 13 17 16\n",
            " 12 18 12 14 16 17 16 16 14 18 14 13 13 16 17 12 16 18 12 13 14 17 12 17\n",
            " 14 18 12 18 16 16 17 17 12 12 12 16 18 16 16 12 14 16 16 14 14 13 13 13\n",
            " 13 16 13 16 16 16 16 16 14 12 16 18 16 13 18 18 14 14 13 13 16 14 14 16\n",
            " 16 17 13 16 13 13 12 14 12 16 12 18 12 17 13 12 13 17 18 12 12 12 16 14\n",
            " 13 13 16 17 17 18 18 13 13 16 18 14 12 18 18 18 18 18 17 16 12 13 16 17\n",
            " 14 13 18 18 17 14 18 13 14 14 13 13 13 17 14 16 18 14 16 16 14 18 18 14\n",
            " 16 18 13 16 13 14 16 16 13 14 13 16 12 12 13 16 13 13 17 17 16 16 18 18\n",
            " 16 14 13 17 14 13 13 18 12 14 14 17 18 12 16 17 16 12 16 16 18 16 17 14\n",
            " 14 13 18 18 18 16 16 17 14 16 12 12 17 18 14 17 17 17 16 16 17 13 17 18\n",
            " 14 12 12 18 13 13 12 12 14 17 12 17 12 14 14 18 16 16 18 14 17 12 18 16\n",
            " 13 13 13 16 12 12 13 17 13 13 13 17 14 16 12 18] [[3.62290285e-16 3.73941779e-16 4.46080478e-16 ... 3.82961463e-16\n",
            "  3.48187954e-16 4.26065593e-16]\n",
            " [2.61203320e-19 2.17812708e-19 3.30445187e-19 ... 3.69715587e-19\n",
            "  3.05919799e-19 5.02164858e-19]\n",
            " [2.68340228e-15 3.99289256e-15 3.12710694e-15 ... 3.28155853e-15\n",
            "  3.60968681e-15 4.07321458e-15]\n",
            " ...\n",
            " [1.67042706e-16 1.43056996e-16 1.05688225e-16 ... 8.85990375e-17\n",
            "  1.52175941e-16 1.27179774e-16]\n",
            " [2.45832043e-15 2.49209439e-15 2.26820346e-15 ... 2.62366528e-15\n",
            "  2.19771401e-15 2.79400679e-15]\n",
            " [3.26830598e-12 3.14515601e-12 3.71626905e-12 ... 4.74877689e-12\n",
            "  3.55012244e-12 3.70213409e-12]] [14 12 17 14 17 14 13 14 16 16 17 13 16 18 18 17 13 17 16 17 14 16 16 14\n",
            " 18 18 18 17 17 14 14 16 17 17 12 16 12 13 17 18 12 13 13 14 13 17 14 12\n",
            " 16 18 18 16 13 13 17 18 17 14 13 14 14 16 12 13 12 17 17 12 16 16 13 14\n",
            " 13 18 12 17 17 17 14 16 13 12 18 17 16 13 13 14 17 17 12 12 14 12 12 17\n",
            " 17 17 18 18 18 12 16 13 13 14 18 12 16 18 12 12 17 14 17 13 16 17 12 16\n",
            " 18 12 18 14 18 16 13 13 13 12 13 14 12 13 17 12 16 17 12 13 16 14 14 16\n",
            " 18 17 17 17 17 17 13 13 12 16 18 12 13 18 16 14 18 18 18 13 12 13 13 13\n",
            " 17 18 16 16 13 12 12 16 17 18 16 16 14 14 14 14 18 12 16 13 17 16 14 17\n",
            " 13 14 14 13 16 17 12 18 14 16 16 18 14 12 17 14 12 18 12 18 14 18 12 18\n",
            " 12 14 14 12 12 14 17 17 18 16 14 13 12 12 16 13 14 16 14 18 18 12 18 18\n",
            " 14 17 13 17 17 17 13 13 16 13 18 16 12 12 18 18 16 16 17 13 13 16 14 16\n",
            " 16 12 13 18 12 18 17 16 16 17 12 16 17 14 16 12 12 13 16 16 13 16 12 13\n",
            " 13 12 17 17 18 17 17 13 13 14 14 12 12 12 13 16 14 13 12 16 16 17 13 13\n",
            " 16 18 13 16 18 16 18 13 13 17 17 13 13 12 18 13 13 18 17 16 17 18 18 16\n",
            " 14 16 14 17 14 13 16 17 13 16 16 14 17 17 18 13 13 18 18 12 16 14 13 14\n",
            " 13 12 13 13 13 13 13 14 14 14 14 14 13 13 16 18 17 12 12 18 12 18 18 16\n",
            " 16 17 16 16 16 17 17 14 12 18 16 16 18 16 12 13 18 13 18 17 16 17 14 16\n",
            " 13 17 18 13 12 14 16 18 18 17 14 12 14 17 12 14 18 17 17 16 18 18 16 17\n",
            " 17 13 16 13 17 12 18 13 18 14 12 13 18 13 18 14 13 17 17 17 17 13 12 17\n",
            " 18 14 13 14 12 13 18 16 13 13 18 18 18 16 14 16 16 12 17 13 12 17 13 12\n",
            " 18 18 14 14 13 18 12 14 18 12 17 18 18 13 13 17 17 18 14 14 17 13 12 14\n",
            " 12 17 18 16 16 18 18 16 18 18 16 12 12 18 14 13 16 16 14 14 13 14 16 13\n",
            " 13 14 13 13 13 16 12 13 18 14 14 18 13 16 14 14 17 13 17 13 14 18 18 12\n",
            " 16 18 17 14 17 18 18 18 13 18 13 17 18 12 12 17 18 16 18 18 17 17 16 12\n",
            " 18 14 18 18 14 14 13 17 18 18 13 14 18 18 16 14 16 13 12 12 16 12 13 18\n",
            " 18 18 17 17 16 13 17 14 17 18 17 16 12 13 12 16 17 14 13 16 13 16 16 17\n",
            " 12 18 12 12 18 18 12 18 18 17 13 13 13 17 14 12 13 13 18 16 13 13 14 16\n",
            " 17 18 12 13 17 17 13 12 17 17 13 17 17 17 13 18 18 12 16 16 16 18 18 18\n",
            " 16 12 17 12 16 14 14 17 17 17 17 16 12 13 12 16 12 14 13 12 12 16 13 13\n",
            " 13 18 17 18 14 14 12 12 16 14 14 12 16 14 13 13 17 17 14 13 14 16 14 16\n",
            " 13 14 13 16 16 13 16 12 13 12 18 18 17 16 16 14 12 12 12 17 13 13 17 18\n",
            " 12 18 12 14 16 17 16 16 14 18 13 13 13 16 13 12 16 18 12 13 14 17 12 17\n",
            " 14 18 12 18 16 16 17 17 12 12 12 16 18 16 16 12 14 16 16 14 14 13 13 13\n",
            " 12 16 13 16 16 16 16 16 14 12 16 18 16 13 18 18 14 14 13 13 16 14 14 16\n",
            " 16 17 13 16 13 13 12 14 12 16 12 18 12 17 13 12 13 17 18 12 12 12 16 14\n",
            " 13 13 16 17 17 18 18 12 13 16 18 14 12 18 18 18 18 18 17 16 12 13 16 17\n",
            " 14 13 18 18 17 14 18 13 14 14 13 13 13 17 14 16 18 14 16 18 14 18 18 14\n",
            " 16 17 13 16 13 14 16 16 13 14 13 16 12 12 13 16 13 13 17 17 16 16 18 18\n",
            " 16 14 13 17 14 13 13 18 12 14 14 17 18 12 16 17 16 12 16 16 18 16 17 14\n",
            " 14 13 18 18 18 16 16 17 14 16 12 12 17 18 14 17 17 17 16 16 17 13 17 18\n",
            " 14 12 12 18 13 13 12 12 14 17 12 17 12 14 14 18 16 16 18 14 17 12 18 16\n",
            " 13 13 13 16 12 12 13 17 13 13 13 17 14 16 12 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKE5nFxguKN7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}