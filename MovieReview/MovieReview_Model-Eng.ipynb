{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieReview-Model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNigSrCGNRw"
      },
      "source": [
        "## RNN\n",
        "현재 정보가 이전 정보가 점층적으로 쌓이면서 정보를 표현할 수 있는 모델이다.    \n",
        "현재 정보 - Input State    \n",
        "이전 정보 - Hidden State   \n",
        "\n",
        "입력 문장을 순차적으로 입력만 하고 마지막으로 입력한 시점에 출력 정보를 뽑아 영화 평점을 예측한다.    \n",
        "마지막 스텝에 나온 은닉 상태는 문장 전체 정보가 담긴 정보로 LR 또는 Binary Classification을 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsK-0MnPJkcf"
      },
      "source": [
        "%tensorflow_version 2.x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ueGtx4CaUW"
      },
      "source": [
        "SEED_NUM = 1234 \n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "tf.random.set_seed(SEED_NUM)\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GecfdwmLY6X"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print('REPLICAS: ', strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IvqTO_XCyfh"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/movie-review-data/'\n",
        "TRAIN_INPUT_DATA = 'train_input.npy'\n",
        "TRAIN_LABEL_DATA = 'train_label.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'\n",
        "\n",
        "train_input = np.load(open(DATA_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
        "train_input = pad_sequences(train_input, maxlen=train_input.shape[1])\n",
        "train_label = np.load(open(DATA_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
        "prepro_configs = json.load(open(DATA_PATH + DATA_CONFIGS, 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWCJtHeaD2Ew"
      },
      "source": [
        "model_name = 'rnn_classifier_en'\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 5\n",
        "VALID_SPLIT = 0.1\n",
        "MAX_LEN = train_input.shape[1]\n",
        "\n",
        "kargs = { 'model_name' : model_name,\n",
        "          'vocab_size' : prepro_configs['vocab_size'],\n",
        "          'embedding_dimension' : 100,\n",
        "          'dropout_rate' : 0.2, \n",
        "          'lstm_dimension' : 150,\n",
        "          'dense_dimension' : 150,\n",
        "          'output_dimension' : 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzE0H9JrHLSa"
      },
      "source": [
        "class RNNClassifier(tf.keras.Model):\n",
        "  def __init__(self, **kargs):\n",
        "    super(RNNClassifier, self).__init__(name=kargs['model_name'])\n",
        "    self.embedding = tf.keras.layers.Embedding(input_dim=kargs['vocab_size'],\n",
        "                                               output_dim=kargs['embedding_dimension'])\n",
        "    # return_sequences를 True로 지정할 경우 시퀀스 형태의 Hidden State 벡터가 출력 된다.\n",
        "    self.lstm_1_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'], return_sequences=True)\n",
        "    self.lstm_2_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'])\n",
        "    self.dropout = tf.keras.layers.Dropout(kargs['dropout_rate'])\n",
        "    self.fc1 = tf.keras.layers.Dense(units=kargs['dense_dimension'], activation=tf.keras.activations.tanh)\n",
        "    self.fc2 = tf.keras.layers.Dense(units=kargs['output_dimension'], activation=tf.keras.activations.sigmoid)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.lstm_1_layer(x)\n",
        "    x = self.lstm_2_layer(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrfmgKI4I21i"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = RNNClassifier(**kargs)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW-eZFYFJi9v"
      },
      "source": [
        "import os \n",
        "# earlystop callback추가\n",
        "earlystop_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
        "\n",
        "checkpoint_path = DATA_PATH + model_name + '/weights.h5'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "  print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
        "else:\n",
        "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "  print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
        "\n",
        "# model checkpoint callback 추가 \n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgMTdDRXMTnk"
      },
      "source": [
        "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callbacks, cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MYQBRfQMaE8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def vis(history,name) :\n",
        "    plt.title(f\"{name.upper()}\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel(f\"{name.lower()}\")\n",
        "    value = history.history.get(name)\n",
        "    val_value = history.history.get(f\"val_{name}\",None)\n",
        "    epochs = range(1, len(value)+1)\n",
        "    plt.plot(epochs, value, 'b-', label=f'training {name}')\n",
        "    if val_value is not None :\n",
        "        plt.plot(epochs, val_value, 'r:', label=f'validation {name}')\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.05, 1.2) , fontsize=10 , ncol=1)\n",
        "    \n",
        "def plot_history(history) :\n",
        "    key_value = list(set([i.split(\"val_\")[-1] for i in list(history.history.keys())]))\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for idx , key in enumerate(key_value) :\n",
        "        plt.subplot(1, len(key_value), idx+1)\n",
        "        vis(history, key)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE1WZoVSNAhy"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3bq8bElPQ3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}